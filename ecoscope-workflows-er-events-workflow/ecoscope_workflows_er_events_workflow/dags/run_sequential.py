# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details
import json
import os

from ecoscope_workflows_core.tasks.filter import set_time_range
from ecoscope_workflows_core.tasks.io import set_er_connection
from ecoscope_workflows_core.tasks.results import gather_output_files
from ecoscope_workflows_ext_custom.tasks.io import persist_df_wrapper
from ecoscope_workflows_ext_custom.tasks.transformation import drop_column_prefix
from ecoscope_workflows_ext_ecoscope.tasks.io import get_events
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_reloc_coord_filter,
    normalize_column,
)

from ..params import Params


def main(params: Params):
    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    time_range = (
        set_time_range.validate()
        .set_task_instance_id("time_range")
        .handle_errors()
        .with_tracing()
        .partial(time_format="%Y-%m-%d", **(params_dict.get("time_range") or {}))
        .call()
    )

    er_client_name = (
        set_er_connection.validate()
        .set_task_instance_id("er_client_name")
        .handle_errors()
        .with_tracing()
        .partial(**(params_dict.get("er_client_name") or {}))
        .call()
    )

    get_event_data = (
        get_events.validate()
        .set_task_instance_id("get_event_data")
        .handle_errors()
        .with_tracing()
        .partial(
            client=er_client_name,
            time_range=time_range,
            event_columns=[
                "id",
                "time",
                "event_type",
                "event_category",
                "reported_by",
                "serial_number",
                "geometry",
                "event_details",
            ],
            raise_on_empty=False,
            include_details=True,
            include_updates=False,
            include_related_events=False,
            include_null_geometry=True,
            **(params_dict.get("get_event_data") or {}),
        )
        .call()
    )

    filter_events = (
        apply_reloc_coord_filter.validate()
        .set_task_instance_id("filter_events")
        .handle_errors()
        .with_tracing()
        .partial(
            df=get_event_data,
            roi_gdf=None,
            roi_name=None,
            **(params_dict.get("filter_events") or {}),
        )
        .call()
    )

    normalize_event_details = (
        normalize_column.validate()
        .set_task_instance_id("normalize_event_details")
        .handle_errors()
        .with_tracing()
        .partial(
            df=filter_events,
            column="event_details",
            **(params_dict.get("normalize_event_details") or {}),
        )
        .call()
    )

    event_cleanup = (
        drop_column_prefix.validate()
        .set_task_instance_id("event_cleanup")
        .handle_errors()
        .with_tracing()
        .partial(
            df=normalize_event_details,
            prefix="event_details__",
            **(params_dict.get("event_cleanup") or {}),
        )
        .call()
    )

    persist_events = (
        persist_df_wrapper.validate()
        .set_task_instance_id("persist_events")
        .handle_errors()
        .with_tracing()
        .partial(
            df=event_cleanup,
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            **(params_dict.get("persist_events") or {}),
        )
        .call()
    )

    output_files = (
        gather_output_files.validate()
        .set_task_instance_id("output_files")
        .handle_errors()
        .with_tracing()
        .partial(files=persist_events, **(params_dict.get("output_files") or {}))
        .call()
    )

    return output_files
